{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea5a2fd6",
   "metadata": {},
   "source": [
    "# Synthetic Data Project – End-to-End Pipeline\n",
    "Covers Questions 2–9: generation, errors, modules, cleaning, visuals, stats, augmentation, models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000304df",
   "metadata": {},
   "source": [
    "## Setup Project Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bc887a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, sys, textwrap, traceback, json\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ROOT = Path(\"./synth_project\")\n",
    "DATA_RAW = ROOT / \"data\" / \"raw\"\n",
    "DATA_PROCESSED = ROOT / \"data\" / \"processed\"\n",
    "MODELS = ROOT / \"models\"\n",
    "RESULTS = ROOT / \"results\"\n",
    "LOGS = ROOT / \"logs\"\n",
    "PLOTS = ROOT / \"plots\"\n",
    "PKG = ROOT / \"synthpkg\"\n",
    "\n",
    "for d in [DATA_RAW, DATA_PROCESSED, MODELS, RESULTS, LOGS, PLOTS, PKG]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print('Project root:', ROOT.resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f6ba0a",
   "metadata": {},
   "source": [
    "## Q4 – Create Minimal Package (`synthpkg`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4cae37",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import textwrap\n",
    "\n",
    "# __init__.py\n",
    "(Path(PKG) / \"__init__.py\").write_text(\"# synthpkg package\\n\")\n",
    "\n",
    "# stats.py\n",
    "(Path(PKG) / \"stats.py\").write_text(\n",
    "    \"import numpy as np\\n\\n\"\n",
    "    \"def mean(arr):\\n\"\n",
    "    \"    arr = np.asarray(arr, dtype=float)\\n\"\n",
    "    \"    return float(np.nanmean(arr))\\n\\n\"\n",
    "    \"def median(arr):\\n\"\n",
    "    \"    arr = np.asarray(arr, dtype=float)\\n\"\n",
    "    \"    return float(np.nanmedian(arr))\\n\\n\"\n",
    "    \"def std(arr):\\n\"\n",
    "    \"    arr = np.asarray(arr, dtype=float)\\n\"\n",
    "    \"    return float(np.nanstd(arr, ddof=0))\\n\"\n",
    ")\n",
    "\n",
    "# augment.py\n",
    "(Path(PKG) / \"augment.py\").write_text(\n",
    "    \"import numpy as np\\n\"\n",
    "    \"import pandas as pd\\n\\n\"\n",
    "    \"def augment_df(df, numeric_cols, target_col=None, scale=1.0, noise_frac=0.02, target_size_factor=2.0, random_state=42):\\n\"\n",
    "    \"    rng = np.random.default_rng(random_state)\\n\"\n",
    "    \"    n_original = len(df)\\n\"\n",
    "    \"    n_target = int(np.ceil(target_size_factor * n_original))\\n\"\n",
    "    \"    idx = rng.integers(low=0, high=n_original, size=n_target)\\n\"\n",
    "    \"    df_aug = df.iloc[idx].copy().reset_index(drop=True)\\n\"\n",
    "    \"    for col in numeric_cols:\\n\"\n",
    "    \"        col_std = df[col].std(ddof=0)\\n\"\n",
    "    \"        noise = rng.normal(loc=0.0, scale=max(1e-12, noise_frac * col_std * scale), size=len(df_aug))\\n\"\n",
    "    \"        df_aug[col] = df_aug[col].astype(float) + noise\\n\"\n",
    "    \"    return df_aug\\n\"\n",
    ")\n",
    "\n",
    "# visuals.py\n",
    "(Path(PKG) / \"visuals.py\").write_text(\n",
    "    \"import numpy as np\\n\"\n",
    "    \"import pandas as pd\\n\"\n",
    "    \"import matplotlib.pyplot as plt\\n\\n\"\n",
    "    \"def save_histogram(series, out_path, bins=30, title=None, xlabel=None):\\n\"\n",
    "    \"    fig, ax = plt.subplots(figsize=(6,4))\\n\"\n",
    "    \"    ax.hist(series.dropna(), bins=bins)\\n\"\n",
    "    \"    ax.set_title(title or f'Histogram of {series.name}')\\n\"\n",
    "    \"    ax.set_xlabel(xlabel or series.name)\\n\"\n",
    "    \"    ax.set_ylabel('Frequency')\\n\"\n",
    "    \"    fig.tight_layout()\\n\"\n",
    "    \"    fig.savefig(out_path, dpi=150)\\n\"\n",
    "    \"    plt.close(fig)\\n\\n\"\n",
    "    \"def save_bar_counts(series, out_path, title=None, xlabel=None):\\n\"\n",
    "    \"    counts = series.value_counts(dropna=False)\\n\"\n",
    "    \"    fig, ax = plt.subplots(figsize=(6,4))\\n\"\n",
    "    \"    ax.bar(counts.index.astype(str), counts.values)\\n\"\n",
    "    \"    ax.set_title(title or f'Counts of {series.name}')\\n\"\n",
    "    \"    ax.set_xlabel(xlabel or series.name)\\n\"\n",
    "    \"    ax.set_ylabel('Count')\\n\"\n",
    "    \"    ax.tick_params(axis='x', rotation=45)\\n\"\n",
    "    \"    fig.tight_layout()\\n\"\n",
    "    \"    fig.savefig(out_path, dpi=150)\\n\"\n",
    "    \"    plt.close(fig)\\n\\n\"\n",
    "    \"def save_scatter(x, y, out_path, title=None, xlabel=None, ylabel=None):\\n\"\n",
    "    \"    fig, ax = plt.subplots(figsize=(6,4))\\n\"\n",
    "    \"    ax.scatter(x, y, s=10)\\n\"\n",
    "    \"    ax.set_title(title or 'Scatter Plot')\\n\"\n",
    "    \"    ax.set_xlabel(xlabel or getattr(x, 'name', 'x'))\\n\"\n",
    "    \"    ax.set_ylabel(ylabel or getattr(y, 'name', 'y'))\\n\"\n",
    "    \"    fig.tight_layout()\\n\"\n",
    "    \"    fig.savefig(out_path, dpi=150)\\n\"\n",
    "    \"    plt.close(fig)\\n\\n\"\n",
    "    \"def save_corr_heatmap(df, out_path, title='Correlation Heatmap'):\\n\"\n",
    "    \"    corr = df.corr(numeric_only=True)\\n\"\n",
    "    \"    fig, ax = plt.subplots(figsize=(6,5))\\n\"\n",
    "    \"    cax = ax.imshow(corr.values, interpolation='nearest')\\n\"\n",
    "    \"    ax.set_title(title)\\n\"\n",
    "    \"    ax.set_xticks(range(len(corr.columns)))\\n\"\n",
    "    \"    ax.set_yticks(range(len(corr.columns)))\\n\"\n",
    "    \"    ax.set_xticklabels(corr.columns, rotation=90)\\n\"\n",
    "    \"    ax.set_yticklabels(corr.columns)\\n\"\n",
    "    \"    fig.colorbar(cax, ax=ax, fraction=0.046, pad=0.04)\\n\"\n",
    "    \"    fig.tight_layout()\\n\"\n",
    "    \"    fig.savefig(out_path, dpi=150)\\n\"\n",
    "    \"    plt.close(fig)\\n\"\n",
    ")\n",
    "\n",
    "# generator.py\n",
    "(Path(PKG) / \"generator.py\").write_text(\n",
    "    \"import numpy as np\\n\"\n",
    "    \"import pandas as pd\\n\"\n",
    "    \"from pathlib import Path\\n\"\n",
    "    \"from datetime import datetime\\n\\n\"\n",
    "    \"class InvalidPathError(Exception):\\n\"\n",
    "    \"    pass\\n\\n\"\n",
    "    \"class DataGenerationError(Exception):\\n\"\n",
    "    \"    pass\\n\\n\"\n",
    "    \"class DataGenerator:\\n\"\n",
    "    \"    def __init__(self, out_csv, log_file=None, random_state=42):\\n\"\n",
    "    \"        self.out_csv = Path(out_csv)\\n\"\n",
    "    \"        self.log_file = Path(log_file) if log_file else None\\n\"\n",
    "    \"        self.rng = np.random.default_rng(random_state)\\n\\n\"\n",
    "    \"    def _log_error(self, msg):\\n\"\n",
    "    \"        if self.log_file is not None:\\n\"\n",
    "    \"            self.log_file.parent.mkdir(parents=True, exist_ok=True)\\n\"\n",
    "    \"            with open(self.log_file, 'a', encoding='utf-8') as f:\\n\"\n",
    "    \"                f.write(f'[{datetime.now().isoformat()}] {msg}\\n')\\n\\n\"\n",
    "    \"    def generate(self, n_rows=500, introduce_nans=True):\\n\"\n",
    "    \"        out_dir = self.out_csv.parent\\n\"\n",
    "    \"        if not out_dir.exists():\\n\"\n",
    "    \"            msg = f'Invalid output directory: {out_dir}'\\n\"\n",
    "    \"            self._log_error(msg)\\n\"\n",
    "    \"            raise InvalidPathError(msg)\\n\\n\"\n",
    "    \"        if not isinstance(n_rows, int) or n_rows <= 0:\\n\"\n",
    "    \"            msg = f'n_rows must be a positive integer. Got: {n_rows}'\\n\"\n",
    "    \"            self._log_error(msg)\\n\"\n",
    "    \"            raise DataGenerationError(msg)\\n\\n\"\n",
    "    \"        try:\\n\"\n",
    "    \"            age = self.rng.integers(18, 80, size=n_rows)\\n\"\n",
    "    \"            income = self.rng.normal(70000, 20000, size=n_rows).clip(15000, None)\\n\"\n",
    "    \"            account_balance = self.rng.normal(15000, 8000, size=n_rows).clip(0, None)\\n\"\n",
    "    \"            visits_last_month = self.rng.poisson(3, size=n_rows)\\n\"\n",
    "    \"            avg_session_minutes = self.rng.normal(12, 6, size=n_rows).clip(0.5, None)\\n\\n\"\n",
    "    \"            gender = self.rng.choice(['Male', 'Female', 'Other'], size=n_rows, p=[0.48, 0.48, 0.04])\\n\"\n",
    "    \"            product_type = self.rng.choice(['Basic', 'Plus', 'Premium'], size=n_rows, p=[0.5, 0.3, 0.2])\\n\\n\"\n",
    "    \"            prob_purchase = (0.2 + 0.000006*(income-30000) + 0.05*(visits_last_month>2).astype(float) + \"\n",
    "    \"                             0.01*(avg_session_minutes>10).astype(float) + 0.05*(product_type=='Premium').astype(float))\\n\"\n",
    "    \"            import numpy as _np\\n\"\n",
    "    \"            prob_purchase = _np.clip(prob_purchase, 0.01, 0.95)\\n\"\n",
    "    \"            purchased = (self.rng.random(n_rows) < prob_purchase).astype(int)\\n\\n\"\n",
    "    \"            df = pd.DataFrame({\"\n",
    "    \"'age': age, \"\n",
    "    \"'income': income.round(2), \"\n",
    "    \"'account_balance': account_balance.round(2), \"\n",
    "    \"'visits_last_month': visits_last_month, \"\n",
    "    \"'avg_session_minutes': avg_session_minutes.round(2), \"\n",
    "    \"'gender': gender, \"\n",
    "    \"'product_type': product_type, \"\n",
    "    \"'purchased': purchased\"\n",
    "    \"})\\n\\n\"\n",
    "    \"            if introduce_nans:\\n\"\n",
    "    \"                num_cols = ['age','income','account_balance','visits_last_month','avg_session_minutes']\\n\"\n",
    "    \"                for col in num_cols:\\n\"\n",
    "    \"                    mask_col = (self.rng.random(n_rows) < 0.006)\\n\"\n",
    "    \"                    df.loc[mask_col, col] = _np.nan\\n\"\n",
    "    \"                cat_mask = self.rng.random(n_rows) < 0.01\\n\"\n",
    "    \"                df.loc[cat_mask, 'gender'] = _np.nan\\n\\n\"\n",
    "    \"            df.to_csv(self.out_csv, index=False)\\n\"\n",
    "    \"            return df\\n\\n\"\n",
    "    \"        except Exception as e:\\n\"\n",
    "    \"            msg = f'Unexpected error during generation: {repr(e)}'\\n\"\n",
    "    \"            self._log_error(msg)\\n\"\n",
    "    \"            raise DataGenerationError(msg) from e\\n\"\n",
    ")\n",
    "print('Package created at:', PKG.resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b70966",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "sys.path.insert(0, str(Path(ROOT).resolve()))\n",
    "from synthpkg.generator import DataGenerator, InvalidPathError, DataGenerationError\n",
    "from synthpkg import stats as sp_stats\n",
    "from synthpkg import augment as sp_aug\n",
    "from synthpkg import visuals as sp_vis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b40cd5e",
   "metadata": {},
   "source": [
    "## Q2 & Q3 – Generate Data + Exception Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d0bd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "raw_csv = DATA_RAW / \"generated_data.csv\"\n",
    "log_file = LOGS / \"errors.txt\"\n",
    "\n",
    "# Successful generation\n",
    "gen = DataGenerator(out_csv=raw_csv, log_file=log_file, random_state=7)\n",
    "df_raw = gen.generate(n_rows=800, introduce_nans=True)\n",
    "print(\"Saved:\", raw_csv.resolve())\n",
    "\n",
    "# Intentional failing generation for screenshot/logging\n",
    "invalid_csv = ROOT / \"not_a_real_dir\" / \"generated_data.csv\"\n",
    "gen_bad = DataGenerator(out_csv=invalid_csv, log_file=log_file, random_state=7)\n",
    "\n",
    "try:\n",
    "    gen_bad.generate(n_rows=200)\n",
    "except Exception as e:\n",
    "    import traceback\n",
    "    trace = traceback.format_exc()\n",
    "    print(\"Captured error (as expected):\\n\", trace)\n",
    "\n",
    "# Save a text screenshot of the traceback\n",
    "def save_text_as_image(text, out_path, title=\"Error Handling Screenshot\"):\n",
    "    fig, ax = plt.subplots(figsize=(10,6))\n",
    "    ax.axis('off')\n",
    "    import textwrap as tw\n",
    "    wrapped = tw.fill(text, width=110)\n",
    "    ax.text(0.01, 0.95, title, fontsize=14, va='top', fontfamily='monospace')\n",
    "    ax.text(0.01, 0.88, wrapped, fontsize=10, va='top', fontfamily='monospace')\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(out_path, dpi=150, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "\n",
    "error_img = LOGS / \"error_screenshot.png\"\n",
    "save_text_as_image(trace, error_img)\n",
    "print(\"Error screenshot saved:\", error_img.resolve())\n",
    "print(\"Error log path:\", log_file.resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d824e5",
   "metadata": {},
   "source": [
    "## Q5 – Data Preparation with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb94f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(raw_csv)\n",
    "\n",
    "def save_df_head_as_image(df_, out_path, title=\"DataFrame Head\"):\n",
    "    fig, ax = plt.subplots(figsize=(10,3))\n",
    "    ax.axis('off')\n",
    "    ax.set_title(title)\n",
    "    table = ax.table(cellText=df_.head(10).values, colLabels=df_.columns, loc='center')\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(8)\n",
    "    table.scale(1, 1.5)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(out_path, dpi=150, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "\n",
    "before_img = PLOTS / \"before_cleaning.png\"\n",
    "save_df_head_as_image(df, before_img, title=\"Before Cleaning (head)\")\n",
    "\n",
    "numeric_cols = ['age','income','account_balance','visits_last_month','avg_session_minutes']\n",
    "categorical_cols = ['gender','product_type']\n",
    "target_col = 'purchased'\n",
    "\n",
    "for col in numeric_cols:\n",
    "    df[col].fillna(df[col].median(), inplace=True)\n",
    "\n",
    "for col in categorical_cols:\n",
    "    mode_val = df[col].mode(dropna=True)\n",
    "    if len(mode_val) > 0:\n",
    "        df[col].fillna(mode_val.iloc[0], inplace=True)\n",
    "    else:\n",
    "        df[col].fillna(\"Unknown\", inplace=True)\n",
    "\n",
    "df_clean = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "clean_csv = DATA_PROCESSED / \"cleaned_data.csv\"\n",
    "df_clean.to_csv(clean_csv, index=False)\n",
    "\n",
    "after_img = PLOTS / \"after_cleaning.png\"\n",
    "save_df_head_as_image(df_clean, after_img, title=\"After Cleaning + Encoding (head)\")\n",
    "\n",
    "print(\"Cleaned CSV:\", clean_csv.resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d32fda",
   "metadata": {},
   "source": [
    "## Q6 – Visualization with Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceaac644",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sp_vis.save_histogram(df['age'], PLOTS / \"hist_age.png\", bins=20, title=\"Age Distribution\")\n",
    "sp_vis.save_bar_counts(df['product_type'], PLOTS / \"bar_product_type.png\", title=\"Product Type Counts\")\n",
    "sp_vis.save_corr_heatmap(df_clean[['age','income','account_balance','visits_last_month','avg_session_minutes']], PLOTS / \"corr_heatmap.png\")\n",
    "sp_vis.save_scatter(df['income'], df['account_balance'], PLOTS / \"scatter_income_balance.png\", title=\"Income vs Account Balance\")\n",
    "\n",
    "print(\"Plots saved to:\", PLOTS.resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa46e6e",
   "metadata": {},
   "source": [
    "## Q7 – Statistics & Augmentation with NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a31fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mean_age = sp_stats.mean(df['age']); median_age = sp_stats.median(df['age']); std_age = sp_stats.std(df['age'])\n",
    "mean_income = sp_stats.mean(df['income']); median_income = sp_stats.median(df['income']); std_income = sp_stats.std(df['income'])\n",
    "\n",
    "print(\"Age  -> mean:\", mean_age, \"median:\", median_age, \"std:\", std_age)\n",
    "print(\"Income -> mean:\", mean_income, \"median:\", median_income, \"std:\", std_income)\n",
    "\n",
    "numeric_cols_for_noise = ['age','income','account_balance','visits_last_month','avg_session_minutes']\n",
    "df_aug = sp_aug.augment_df(df_clean, numeric_cols=numeric_cols_for_noise, target_col='purchased',\n",
    "                           scale=1.0, noise_frac=0.02, target_size_factor=2.0, random_state=7)\n",
    "aug_csv = DATA_PROCESSED / \"augmented_data.csv\"\n",
    "df_aug.to_csv(aug_csv, index=False)\n",
    "print(\"Augmented CSV:\", aug_csv.resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b83589",
   "metadata": {},
   "source": [
    "## Q8 – Model Training (Logistic Regression & Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a72a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "def train_and_evaluate(df_ml, dataset_name, target_col='purchased'):\n",
    "    X = df_ml.drop(columns=[target_col])\n",
    "    y = df_ml[target_col].astype(int)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7, stratify=y)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    pipe_lr = Pipeline([(\"scaler\", StandardScaler(with_mean=False)), (\"lr\", LogisticRegression(max_iter=200, solver='liblinear'))])\n",
    "    pipe_lr.fit(X_train, y_train)\n",
    "    y_pred_lr = pipe_lr.predict(X_test)\n",
    "    y_proba_lr = pipe_lr.predict_proba(X_test)[:,1]\n",
    "    results.append({\n",
    "        \"dataset\": dataset_name, \"model\": \"LogisticRegression\",\n",
    "        \"accuracy\": accuracy_score(y_test, y_pred_lr),\n",
    "        \"precision\": precision_score(y_test, y_pred_lr),\n",
    "        \"recall\": recall_score(y_test, y_pred_lr),\n",
    "        \"f1\": f1_score(y_test, y_pred_lr),\n",
    "        \"roc_auc\": roc_auc_score(y_test, y_proba_lr),\n",
    "    })\n",
    "    joblib.dump(pipe_lr, MODELS / f\"logreg_{dataset_name}.joblib\")\n",
    "\n",
    "    rf = RandomForestClassifier(n_estimators=200, random_state=7)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred_rf = rf.predict(X_test)\n",
    "    y_proba_rf = rf.predict_proba(X_test)[:,1]\n",
    "    results.append({\n",
    "        \"dataset\": dataset_name, \"model\": \"RandomForest\",\n",
    "        \"accuracy\": accuracy_score(y_test, y_pred_rf),\n",
    "        \"precision\": precision_score(y_test, y_pred_rf),\n",
    "        \"recall\": recall_score(y_test, y_pred_rf),\n",
    "        \"f1\": f1_score(y_test, y_pred_rf),\n",
    "        \"roc_auc\": roc_auc_score(y_test, y_proba_rf),\n",
    "    })\n",
    "    joblib.dump(rf, MODELS / f\"rf_{dataset_name}.joblib\")\n",
    "    return results\n",
    "\n",
    "import pandas as pd\n",
    "df_clean = pd.read_csv(DATA_PROCESSED / \"cleaned_data.csv\")\n",
    "df_aug = pd.read_csv(DATA_PROCESSED / \"augmented_data.csv\")\n",
    "\n",
    "metrics_clean = train_and_evaluate(df_clean, \"cleaned\")\n",
    "metrics_aug = train_and_evaluate(df_aug, \"augmented\")\n",
    "\n",
    "all_metrics = pd.DataFrame(metrics_clean + metrics_aug)\n",
    "all_metrics.to_csv(RESULTS / \"metrics.csv\", index=False)\n",
    "\n",
    "best_row = all_metrics.sort_values(by=[\"f1\",\"roc_auc\"], ascending=False).iloc[0]\n",
    "print(\"Best model:\", best_row.to_dict())\n",
    "print(\"Metrics saved to:\", (RESULTS / \"metrics.csv\").resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c654bd3",
   "metadata": {},
   "source": [
    "## Q9 – Generate a Short Report (Markdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f998c27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "report_md = ROOT / \"report.md\"\n",
    "report_md.write_text(\n",
    "    \"# Synthetic Data Project – Report\\n\\n\"\n",
    "    f\"- Outputs saved under `{ROOT.resolve()}`.\\n\"\n",
    "    \"- OOP, exceptions, modules, cleaning, plots, stats, augmentation, and model training done.\\n\"\n",
    "    \"- See `results/metrics.csv` for model comparisons; `plots/` for figures; `logs/` for error logs and screenshot.\\n\"\n",
    ")\n",
    "print(\"Report saved to:\", report_md.resolve())\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
